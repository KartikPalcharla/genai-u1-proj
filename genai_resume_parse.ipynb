{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml8KmceguoRU",
        "outputId": "56210b47-3f28-431d-f67d-7298af2bce91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing resume...\n",
            "\n",
            "--- ðŸ“„ Parse Results ---\n",
            "{\n",
            "    \"Candidate Name\": \"John Smith\",\n",
            "    \"Companies\": [\n",
            "        \"Microsoft\",\n",
            "        \"Amazon\"\n",
            "    ],\n",
            "    \"Universities\": [\n",
            "        \"PES University\"\n",
            "    ],\n",
            "    \"Locations\": [\n",
            "        \"WA\",\n",
            "        \"Seattle\",\n",
            "        \"Tokyo\",\n",
            "        \"London\",\n",
            "        \"Redmond\"\n",
            "    ],\n",
            "    \"Detected Skills\": [\n",
            "        \"Java\",\n",
            "        \"Azure\",\n",
            "        \"AWS\"\n",
            "    ],\n",
            "    \"Debug_Log\": [\n",
            "        \"Accepted: John Smith (PER) - 0.90\",\n",
            "        \"Accepted: Microsoft (ORG) - 1.00\",\n",
            "        \"Accepted: Redmond (LOC) - 0.96\",\n",
            "        \"Accepted: WA (LOC) - 1.00\",\n",
            "        \"Accepted: London (LOC) - 1.00\",\n",
            "        \"Accepted: Tokyo (LOC) - 1.00\",\n",
            "        \"Accepted: Amazon (ORG) - 0.99\",\n",
            "        \"Accepted: Seattle (LOC) - 1.00\",\n",
            "        \"Accepted: WA (LOC) - 1.00\",\n",
            "        \"Accepted: PES University (ORG) - 0.93\",\n",
            "        \"Accepted: Seattle (LOC) - 1.00\",\n",
            "        \"Accepted: WA (LOC) - 1.00\"\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import json\n",
        "\n",
        "class ReliableResumeParser:\n",
        "    def __init__(self):\n",
        "        # We stick with the same model, but we will process its output much more strictly\n",
        "        self.ner_pipeline = pipeline(\n",
        "            \"ner\",\n",
        "            model=\"dslim/bert-base-NER\",\n",
        "            aggregation_strategy=\"simple\" # This attempts to join ##tokens\n",
        "        )\n",
        "\n",
        "        # A simple \"Knowledge Base\" to correct the AI's mistakes\n",
        "        # If the AI thinks \"Python\" is a Company, this list will correct it to \"Skill\"\n",
        "        self.known_skills = {\n",
        "            \"Python\", \"Java\", \"C++\", \"SQL\", \"Spark\", \"Kafka\", \"Hadoop\",\n",
        "            \"Docker\", \"Kubernetes\", \"React\", \"AWS\", \"GCP\", \"Azure\",\n",
        "            \"TensorFlow\", \"PyTorch\", \"Pandas\", \"Linux\", \"Git\", \"PostGIS\"\n",
        "        }\n",
        "\n",
        "    def parse(self, resume_text):\n",
        "        print(\"Analyzing resume...\")\n",
        "\n",
        "        # 1. Clean the text slightly (remove excessive tabs/newlines which confuse BERT)\n",
        "        clean_text = \" \".join(resume_text.split())\n",
        "\n",
        "        entities = self.ner_pipeline(clean_text)\n",
        "\n",
        "        data = {\n",
        "            \"Candidate Name\": None,\n",
        "            \"Companies\": [],\n",
        "            \"Universities\": [],\n",
        "            \"Locations\": [],\n",
        "            \"Detected Skills\": [],  # New Category\n",
        "            \"Debug_Log\": []\n",
        "        }\n",
        "\n",
        "        # 2. Iterate with STRICT Logic\n",
        "        for entity in entities:\n",
        "            text = entity['word'].strip()\n",
        "            score = entity['score']\n",
        "            group = entity['entity_group']\n",
        "\n",
        "            # RULE 1: Ignore low confidence garbage (Fixes \"Dock\", \"Ku\", \"##Flow\")\n",
        "            if score < 0.85:\n",
        "                continue\n",
        "\n",
        "            # RULE 2: Ignore tiny tokens (artifacts like \"P\", \"A\")\n",
        "            if len(text) < 2:\n",
        "                continue\n",
        "\n",
        "            # RULE 3: Check our Skills Knowledge Base\n",
        "            # If the text is in our known skills list, force it to 'Skills' regardless of what AI said\n",
        "            if text in self.known_skills:\n",
        "                data[\"Detected Skills\"].append(text)\n",
        "                continue\n",
        "\n",
        "            # RULE 4: Categorization\n",
        "            if group == \"PER\":\n",
        "                # Only accept names if we haven't found one yet (usually the first one is correct)\n",
        "                if data[\"Candidate Name\"] is None:\n",
        "                    data[\"Candidate Name\"] = text\n",
        "\n",
        "            elif group == \"ORG\":\n",
        "                if any(x in text for x in [\"University\", \"College\", \"School\"]):\n",
        "                    data[\"Universities\"].append(text)\n",
        "                else:\n",
        "                    data[\"Companies\"].append(text)\n",
        "\n",
        "            elif group == \"LOC\":\n",
        "                data[\"Locations\"].append(text)\n",
        "\n",
        "            data[\"Debug_Log\"].append(f\"Accepted: {text} ({group}) - {score:.2f}\")\n",
        "\n",
        "        # RULE 5: Fallback for Name\n",
        "        # If AI didn't find a Person, assume the first line of the original text is the name\n",
        "        if data[\"Candidate Name\"] is None:\n",
        "            first_line = resume_text.strip().split('\\n')[0]\n",
        "            # Heuristic: If first line is short (likely a name), use it\n",
        "            if len(first_line) < 30:\n",
        "                data[\"Candidate Name\"] = first_line\n",
        "\n",
        "        # Deduplicate lists\n",
        "        for key in [\"Companies\", \"Universities\", \"Locations\", \"Detected Skills\"]:\n",
        "            data[key] = list(set(data[key]))\n",
        "\n",
        "        return data\n",
        "\n",
        "# --- TEST ---\n",
        "if __name__ == \"__main__\":\n",
        "    real_resume = \"\"\"\n",
        "    John Smith\n",
        "    Seattle | john.smith@email.com\n",
        "\n",
        "EXPERIENCE\n",
        "\n",
        "Software Engineer\n",
        "Microsoft | Redmond, WA\n",
        "2018 - Present\n",
        "- Developed new features for Azure cloud services using C# and .NET.\n",
        "- Collaborated with teams in London and Tokyo to improve server uptime.\n",
        "\n",
        "Junior Developer\n",
        "Amazon | Seattle, WA\n",
        "2016 - 2018\n",
        "- Maintained the internal inventory system using Java and AWS.\n",
        "- Fixed bugs in the checkout process.\n",
        "\n",
        "EDUCATION\n",
        "\n",
        "Bachelor of Science in Computer Science\n",
        "PES University | Seattle, WA\"\"\"\n",
        "\n",
        "    parser = ReliableResumeParser()\n",
        "    result = parser.parse(real_resume)\n",
        "\n",
        "    print(\"\\n--- ðŸ“„ Parse Results ---\")\n",
        "    print(json.dumps(result, indent=4))"
      ]
    }
  ]
}